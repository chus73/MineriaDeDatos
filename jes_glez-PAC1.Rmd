---
title: 'Minería de datos: PEC1'
author: "Autor: Jesús González Leal"
date: "marzo 2021"
output:
  pdf_document:
    highlight: zenburn
    toc: yes
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 75.584-PEC-header.html
  word_document: default
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

------------------------------------------------------------------------

# Introducción

------------------------------------------------------------------------

## Presentación

Esta prueba de evaluación continuada cubre el módulo 1,2 y 8 del
programa de la asignatura.

## Competencias

Las competencias que se trabajan en esta prueba son:

-   Uso y aplicación de las TIC en el ámbito académico y profesional
-   Capacidad para innovar y generar nuevas ideas.
-   Capacidad para evaluar soluciones tecnológicas y elaborar propuestas
    de proyectos teniendo en cuenta los recursos, las alternativas
    disponibles y las condiciones de mercado.
-   Conocer las tecnologías de comunicaciones actuales y emergentes, así
    como saberlas aplicar convenientemente para diseñar y desarrollar
    soluciones basadas en sistemas y tecnologías de la información.
-   Aplicación de las técnicas específicas de ingeniería del software en
    las diferentes etapas del ciclo de vida de un proyecto.
-   Capacidad para aplicar las técnicas específicas de tratamiento,
    almacenamiento y administración de datos.
-   Capacidad para proponer y evaluar diferentes alternativas
    tecnológicas para resolver un problema concreto.
-   Capacidad de utilizar un lenguaje de programación.\
-   Capacidad para desarrollar en una herramienta IDE.\
-   Capacidad de plantear un proyecto de minería de datos.

## Objetivos

-   Asimilar correctamente el módulo 1 y 2.
-   Qué es y qué no es MD.
-   Ciclo de vida de los proyectos de MD.
-   Diferentes tipologías de MD.
-   Conocer las técnicas propias de una fase de preparación de datos y
    objetivos a alcanzar.

## Descripción de la PEC a realizar

La prueba está estructurada en 1 ejercicio teórico/práctico y 1
ejercicio práctico que pide que se desarrolle la fase de preparación en
un juego de datos.\
Deben responderse todos los ejercicios para poder superar la PEC.

## Recursos

Para realizar esta práctica recomendamos como punto de partida la
lectura de los siguientes documentos:

-   Módulo 1, 2 y 8 del material didáctico.
-   Ciclo de vida de un proyecto de minería de datos:
    <https://es.wikipedia.org/wiki/Cross_Industry_Standard_Process_for_Data_Mining>
-   Aparta del enunciado de la actividad disponéis de unos materiales de
    ggplot2
-   El aula laboratorio de R para resolver dudas o problemas.
-   RStudio Cheat Sheet: Disponible en el aula Laboratorio de Minería de
    datos.
-   R Base Cheat Sheet: Disponible en el aula Laboratorio de Minería de
    datos. e \#\# Formato y fecha de entrega El formato de entrega es:
    usernameestudiant-PAC1.html (pdf o word) y rmd. Fecha de Entrega:
    31/03/2021. Se tiene que depositar la PEC en el buzón de entregas
    del aula.

## Nota: Propiedad intelectual

A menudo es inevitable, al producir una obra multimedia, hacer uso de
recursos creados por terceras personas. Es por lo tanto comprensible
hacerlo en el marco de una práctica de los estudios de Informática,
Multimedia y Telecomunicación de la UOC, siempre y cuando esto se
documente claramente y no suponga plagio en la práctica.

Por lo tanto, al presentar una práctica que haga uso de recursos ajenos,
se debe presentar junto con ella un documento en qué se detallen todos
ellos, especificando el nombre de cada recurso, su autor, el lugar dónde
se obtuvo y su estatus legal: si la obra está protegida por el copyright
o se acoge a alguna otra licencia de uso (Creative Commons, licencia
GNU, GPL ...). El estudiante deberá asegurarse de que la licencia no
impide específicamente su uso en el marco de la práctica. En caso de no
encontrar la información correspondiente tendrá que asumir que la obra
está protegida por copyright.

Deberéis, además, adjuntar los ficheros originales cuando las obras
utilizadas sean digitales, y su código fuente si corresponde.

------------------------------------------------------------------------

# Ejemplo de solución del ejercicio 2

------------------------------------------------------------------------

------------------------------------------------------------------------

## Objetivos

------------------------------------------------------------------------

Como ejemplo, trabajaremos con el juego de datos "Titanic.csv" que
recoge datos sobre el famoso crucero.

Las actividades que llevaremos a cabo en esta práctica se realizan en
las fases iniciales de un proyecto de minería de datos. Tienen como
objetivo obtener un dominio de los datos con las que construiremos el
modelo de minería. Tenemos que conocer los datos profundamente tanto en
su formato como contenido. Tareas típicas en esta fase pueden ser la
selección de características o variables, la preparación del juego de
datos para posteriormente ser consumido por un algoritmo e intentar
extraer el máximo conocimiento posible de los datos.

Desarrollaremos un subconjunto de tareas mínimas y de ejemplo. Podemos
incluir muchas más y mucho más profundas, como hemos visto al material
docente.

## Procesos iniciales con los datos

Primero contacto con el juego de datos

Instalamos y cargamos las librerías ggplot2 y dplry

```{r echo=TRUE, message=FALSE, warning=FALSE}
# https://cran.r-project.org/web/packages/ggplot2/index.html
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
```

Cargamos el fichero de datos

```{r}
totalData <- read.csv('titanic.csv',stringsAsFactors = FALSE)
filas=dim(totalData)[1]
```

Cargamos los datos filtrados por tripulación para hacer estudios
posteriores

```{r}
totalData_crew=subset(totalData, totalData$class=="engineering crew")
```

Verificamos la estructura del juego de datos principal

```{r}
str(totalData)
```

Vemos que tenemos 2207 registros que se corresponden a los viajeros y
tripulación del Titánic y 11 variables que los caracterizan.

Revisamos la descripción de las variables contenidas en el fichero y si
los tipos de variable se corresponde al que hemos cargado:

**name** string with the name of the passenger.

**gender** factor with levels male and female.

**age** numeric value with the persons age on the day of the sinking.
The age of babies (under 12 months) is given as a fraction of one year
(1/month).

**class** factor specifying the class for passengers or the type of
service aboard for crew members.

**embarked** factor with the persons place of of embarkment.

**country** factor with the persons home country.

**ticketno** numeric value specifying the persons ticket number (NA for
crew members).

**fare** numeric value with the ticket price (NA for crew members,
musicians and employees of the shipyard company).

**sibsp** ordered factor specifying the number if siblings/spouses
aboard; adopted from Vanderbild data set.

**parch** an ordered factor specifying the number of parents/children
aboard; adopted from Vanderbild data set.

**survived** a factor with two levels (no and yes) specifying whether
the person has survived the sinking.

Vamos ahora a sacar estadísticas básicas y después trabajamos los
atributos con valores vacíos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(totalData)
```

Estadísticas de valores vacíos

```{r}
colSums(is.na(totalData))
colSums(totalData=="")
```

Asignamos valor "Desconocido" para los valores vacíos de la variable
"country"

```{r}
totalData$country[is.na(totalData$country)] <- "Desconocido"
```

Asignamos la media para valores vacíos de la variable "age"

```{r}
totalData$age[is.na(totalData$age)] <- mean(totalData$age,na.rm=T)
```

De la información mostrada destacamos que el pasajero más joven tenía 6
meses y el más grande 74 años. La media de edad la tenían en 30 años.
También podemos ver 891 sin billete. Revisaremos si se corresponde a la
tripulación. También podemos observar el que se pagó por el billete. En
este caso se entienden las discrepancias en la fiabilidad de este dato.
Parece que los pasajeros que embarcaron a Southampton hacían transbordo
de un barco que tenía la tripulación en huelga y por eso no pagaron lo
que explicaría la diferencia. Recordemos que la tripulación no pagaba.
Sibsp y parch también muestran datos interesantes del viajero con quien
más familiares viajaba eran 8 hermanos o mujer y 9 hijos o padre/madre.

Si observamos los NA (valores nulos) vemos que los datos están bastante
bien. Decidimos sustituir el valor NA de country por Desconocido por una
mayor legibilidad. También proponemos sustituir los NA de age por la
media a pesar de que realmente no hace falta.

Es curios como los valores NA de sibsp y parch nos permite deducir que
viajaban muchas familias. De hecho, a simple vista, restante la
tripulación la gente que viajaba sola era mínima. Este dato la podríamos
contrastar también. Sería interesante relacionar la mortalidad del
accidente con el tamaño de las familias que viajaban.

Ahora añadiremos un campo nuevo a los datos. Este campo contendrá el
valor de la edad discretizada con un método simple de intervalos de
igual amplitud.

```{r echo=TRUE, message=FALSE, warning=FALSE}

summary(totalData[,"age"])
```

Discretizamos

```{r}
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
```

Observamos los datos discretizados

```{r}
head(totalData)
```

Vemos como se agrupaban por edad

```{r}
plot(totalData$segmento_edad)
```

Ahora repetimos por el proceso, pero solo por el subconjunto de
tripulación filtrado antes

```{r}
totalData_crew["segmento_edad"] <- cut(totalData_crew$age, breaks = c(0,10,20,30,40,50,60,70,100), labels = c("0-9", "10-19", "20-29", "30-39","40-49","50-59","60-69","70-79"))
plot(totalData_crew$segmento_edad)
```

De la discretización de la edad observamos que realmente la gente que
viajaba era muy joven. El segmento más grande es de 20 a 29 años.
También vemos de la juventud de la tripulación.

## Procesos de análisis visuales del juego de datos

Nos proponemos analizar las relaciones entre las diferentes variables
del juego de datos para ver si se relacionan y como.

Visualizamos la relación entre las variables "gender" y "survived":

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=totalData[1:filas,],aes(x=gender,fill=survived))+geom_bar()
```

Otro punto de vista. Survived como función de Embarked:

```{r}
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+ylab("Frequència")
```

En la primera gráfica podemos observar fácilmente la cantidad de mujeres
que viajaban respecto hombres y observar los que no sobrevivieron.
Numéricamente el número de hombres y mujeres supervivientes es similar.

A la segunda gráfica de forma porcentual observamos los puertos de
embarque y los porcentajes de supervivencia en función del puerto. Se
podría trabajar el puerto C (Cherburgo) para ver de explicar la
diferencia en los datos. Quizás porcentualmente embarcaron más mujeres o
niños... ¿O gente de primera clase?

Obtenemos ahora una matriz de porcentajes de frecuencia. Vemos, por
ejemplo, que la probabilidad de sobrevivir si se embarcó en "C" es de un
56.45%

```{r echo=TRUE, message=FALSE, warning=FALSE}
t<-table(totalData[1:filas,]$embarked,totalData[1:filas,]$survived)
for (i in 1:dim(t)[1]){
    t[i,]<-t[i,]/sum(t[i,])*100
}
```

Veamos ahora como en un mismo gráfico de frecuencias podemos trabajar
con 3 variables: Embarked, Survived y class.

Mostramos el gráfico de embarcados por Pclass:

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = totalData[1:filas,],aes(x=embarked,fill=survived))+geom_bar(position="fill")+facet_wrap(~class)
```

Aquí ya podemos extraer mucha información. Como propuesta de mejora se
podría hacer un gráfico similar trabajando solo la clase. Habría que
unificar toda la tripulación a una única categoría.

Comparamos ahora dos gráficos de frecuencias: Survived-SibSp y
Survived-Parch

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = totalData[1:filas,],aes(x=sibsp,fill=survived))+geom_bar()
ggplot(data = totalData[1:filas,],aes(x=parch,fill=survived))+geom_bar()
```

Vemos como la forma de estos dos gráficos es similar. Este hecho nos
puede indicar presencia de correlaciones altas. Hecho previsible en
función de la descripción de las variables.

Veamos un ejemplo de construcción de una variable nueva: Tamaño de
familia

```{r echo=TRUE, message=FALSE, warning=FALSE}
totalData$FamilySize <- totalData$sibsp + totalData$parch +1;
totalData1<-totalData[1:filas,]
ggplot(data = totalData1[!is.na(totalData[1:filas,]$FamilySize),],aes(x=FamilySize,fill=survived))+geom_histogram(binwidth =1,position="fill")+ylab("Freqüència")
```

Se confirma el hecho de que los pasajeros viajaban mayoritariamente en
familia. No podemos afirmar que el tamaño de la familia tuviera nada que
ver con la posibilidad de sobrevivir pues nos tememos que
estadísticamente el hecho de haber más familias de alrededor de cuatro
miembros debería de ser habitual. Es un punto de partida para investigar
más.

Veamos ahora dos gráficos que nos compara los atributos Age y Survived.
Observamos como el parámetro position="fill" nos da la proporción
acumulada de un atributo dentro de otro.

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = totalData1[!(is.na(totalData[1:filas,]$age)),],aes(x=age,fill=survived))+geom_histogram(binwidth =3)
ggplot(data = totalData1[!is.na(totalData[1:filas,]$age),],aes(x=age,fill=survived))+geom_histogram(binwidth = 3,position="fill")+ylab("Frequencia")
```

Observamos como el parámetro position="fill" nos da la proporción
acumulada de un atributo dentro de otro. Parece que los niños tuvieron
más posibilidad de salvarse.

## Conclusiones finales

Los datos tienen una calidad correcta y están mayoritariamente muy
informadas. Disponen de una variable de clase "survived" que las hace
aptas por un clasificador. A parte de la mayor supervivencia de mujeres
y niños y de pasajeros de primera clase podemos observar la juventud de
los pasajeros y la tripulación. Se observa también una gran cantidad de
personas que viajaban con sus familias.

------------------------------------------------------------------------

# Ejercicios

------------------------------------------------------------------------

## Ejercicio 1:

Propón un proyecto completo de minería de datos. La respuesta tiene que
coincidir con las fases típicas del ciclo de vida de un proyecto de
minería de datos. No hay que desarrollar las tareas de cada fase. Para
cada fase indica cuál es el objetivo de la fase y el producto que se
obtendrá. Utiliza ejemplos de qué y cómo podrían ser las tareas. Si hay
alguna característica que hace diferente el ciclo de vida de un proyecto
de minería respecto a otros proyectos indícalo.

> ### Introducción al Proyecto
>
> Conocer el movimiento y la situación de las personas siempre ha tenido
> especial importancia para poder planificar adecuadamente desde flujos
> migratorios, hasta el número de personas que asisten a las
> concentraciones. Hoy en día nos encontramos con un elemento que cambia
> totalmente el paradigma de como se estaban realizando esta serie de
> estudios hasta el momento. Nos referimos a la incorporación del
> teléfono móvil como parte inseparable del ciudadano. El uso de
> dispositivos móviles por parte de la población trae pareja la
> comunicación con las torres de telefonía. Éstas son capaces de ubicar
> con relativa exactitud la posición dentro de una celda de comunicación
> mediante triangulación, permitiendo la recopilación de datos de manera
> constante y en tiempo real.
>
> Dentro de los objetivos de este proyecto se encuentra el tener un
> modelo que basado en los movimientos del tráfico, pueda predecir la
> saturación de las vías de tráfico con el fin de poder planificar y
> actuar con la suficiente anticipación ante diferentes escenarios, como
> son obras en la red de carreteras, movimientos masivos de la
> población, e incidencias medioambientales que pudieran derivar en un
> colapso circulatorio.
>
> Este proyecto está inspirado en el estudio sobre movilidad realizado
> por el INE a raíz de la pandemia de COVID-19. Dicho estudio se puede
> encontrar en el siguiente enlace:
> <https://www.ine.es/covid/covid_movilidad.htm>
>
> ### Identificación del las fases del proyecto
>
> Utilizando la metodología **CRISP-DM** para el desarrollo de proyectos
> de minería de datos, exploraremos las diferentes fases del proyecto a
> alto nivel, sin entrar a definir las tareas que surgirían dentro de
> cada fase. Esta metodología puede ser consultada en el siguiente
> documento: <https://www.the-modeling-agency.com/crisp-dm.pdf>, y
> consta de seis fases que se van realizando cíclicamente. Por otro
> lado, si en una de las fases se detectasen carencias, se permite la
> realimentación hacia fases previas para poder solucionarlas.
>
> [![Extraído del documento crisp-dm 1.0 pag.
> 12](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-17BA4160.png "Fases del modelo CRISP-DM")](https://www.the-modeling-agency.com/crisp-dm.pdf)
>
> ### Business Understanding
>
> La primera fase del modelo CRISPM-DM comienza con la comprensión del
> negocio y de los **objetivos principales del proyecto**. Durante esta
> fase se realiza un estudio del impacto que tendrá en el negocio, los
> riesgos y contingencias, y el binomio coste - beneficio que
> representará. Como entregables a cumplir tenemos el plan de proyecto
> preliminar necesario para alcanzar el resultado esperado y los
> objetivos mínimos a cumplir.
>
> Tal y como se ha planteado en la introducción del proyecto, la
> posibilidad que nos ofrece hoy en día la tecnología de poder rastrear
> el movimiento de las personas, genera un flujo de información
> aprovechable a nivel empresarial. No obstante, nos encontramos con la
> dificultad de explotar esta información individualmente debido a las
> restricciones impuestas por las leyes de protección de datos que
> impera en toda la Unión Europea. No obstante, para el proyecto que se
> muestra no es necesario contar con una alta granularidad, interesando
> ver los flujos de circulación entre poblaciones.
>
> **Objetivos del negocio:** Tener un modelo que permita predecir los
> flujos del transito entre poblaciones con el fin de poder planificar
> rutas con total eficacia.
>
> **Evaluación de la situación:** Para el desarrollo del proyecto
> contamos principalmente con los datos facilitados por las operadoras
> de telefonía móvil, así como con la información facilitada por la DGT
> y complementada por la agencia metereológica de españa (AEMET). En una
> fase posterior del proyecto y vista su viabilidad, se puede utilizar
> la plataforma de google maps o bien streetopenview para la publicación
> de los resultados.
>
> Será necesario tener en cuenta los **costes de licenciamiento** que
> pedirán las compañías de telefonía por la explotación de los datos.
> Para el resto de plataformas contempladas no se contemplan gastos en
> un inicio. En el caso de la DGT son datos "opendata", y para los datos
> metereológicos, existe una capa de consumo sin coste que se prevee que
> pueda dar servicio al proyecto.
>
> El **retorno de la inversión** se obtendrá de la venta del servicio a
> compañías de transporte. Una vez evaluado el modelo en producción se
> pueden buscar otros nichos de negocio.
>
> Se considerará que el proyecto ha tenido **éxito** si:
>
> -   Se consigue predecir las situaciones de riesgo en la red de
>     carreteras estatales en por encima de un 70%.
>
> -   El proyecto se complementa en plazos y presupuesto.
>
> Todo lo recogido en esta fase constituirá la base para realizar el
> **plan del proyecto**, el cual además contará con un cronograma a alto
> nivel, la descripción de los recursos necesarios y una descripción del
> presupuesto estimado.
>
> +---+------------------------+-----------------+----------------------------------+
> | N | Fase                   | Tiempo estimado | Entregable                       |
> +===+========================+=================+==================================+
> | 1 | Business Understanding | 1 semana        | Plan de proyecto                 |
> +---+------------------------+-----------------+----------------------------------+
> | 2 | Data Understanding     | 1 semanas       | Informe de recopilación de datos |
> +---+------------------------+-----------------+----------------------------------+
> | 3 | Data Preparation       | 3 semana        | modelo lógico                    |
> +---+------------------------+-----------------+----------------------------------+
> | 4 | Modeling               | 2 semanas       | modelo físico                    |
> |   |                        |                 |                                  |
> |   |                        |                 | Plan de pruebas                  |
> +---+------------------------+-----------------+----------------------------------+
> | 5 | Evaluation             | 1 semana        | Resultado Test                   |
> +---+------------------------+-----------------+----------------------------------+
> | 6 | Deployment             | 1 semana        | Documento técnico                |
> +---+------------------------+-----------------+----------------------------------+
>
> La estimación de tiempos se ha realizado con un escenario optimista,
> dejando margen para la redacción de la documentación que acompañe al
> proyecto. En este sentido, se han definido los entregables mínimos que
> aparecen en la tabla superior.
>
> Los **recursos estimados** mínimos serán la de un jefe de proyecto con
> experiencia en analítica avanzada y un data scientist para el
> desarrollo del modelo. La carga del equipo se balanceará y podrá ser
> modificado en función de las exigencias del proyecto.
>
> Se establecen **puntos de control** mínimo con negocio en la
> finalización de cada fase.
>
> ### Data Understanding
>
> Esta fase se busca familiarizarse con la comprensión de los datos,
> identificando los problemas de calidad que puedan tener y descubriendo
> información oculta o los subconjunto interesante de datos a tratar que
> permitan tener una visión desde diferentes perspectivas. Un punto
> importante será verificar la calidad de los datos para definir las
> estrategias necesarias para abordarlos. Al finalizar esta fase ya
> podremos tener un **modelo conceptual** de los datos.
>
> Los **datos iniciales** serán proporcionados por los operadores de
> telefonía. Estas empresas cuentan con nuestros datos personales, así
> como los datos de nuestro terminal, unida a la información del rastro
> de desplazamiento. No obstante, para cumplir con la legislación actual
> en materia de privacidad, esta información a de ser anonimizada
> mediante un procedimiento que impida dentro del contexto tecnológico
> actual la asociación de un determinado dato con un sujeto determinado
> (ver <https://www.aepd.es/es/documento/2008-0283.pdf>).
>
> Si nos fijamos en el set de datos que se preparó para el INE a raíz
> del estudio de movilidad por ámbito geográfico durante el estado de
> alarma por COVID-19, las operadoras generan tres ficheros diarios de
> tipo csv como origen de datos (ver
> <https://www.ine.es/covid/datos_disponibles.zip>):
>
> -   **PobxCeldasOrigen_DDMMM**. Fichero con la descripción de la
>     celda, la población en donde está ubicada, el número de personas
>     residentes, el número de personas que se han desplazado, y
>     porcentajes sobre el total.
>
> -   **PobxCeldasDestino_DDMMM**. Fichero con una estructura similar al
>     anterior, en donde se registra el movimiento entrante en la
>     población registrado por la celda.
>
> -   **Flujos_DDMMM**. Fichero que contempla el flujo entre las
>     diferentes celdas.
>
> Aunque estos datos estáticos nos sirven como ejemplo de datos, [para
> que el proyecto tenga sentido la ventana temporal de entrega del flujo
> tiene que ser en tiempo "quasi" real]{.ul}. Solamente de esta manera
> se tendrá la suficiente antelación como para poder actuar antes de que
> la fotografía registrada esté caducada.
>
> Como complemento a la información recibida se consultan otras fuentes
> de datos:
>
> -   **Incidencias de tráfico de España**. Base de datos que recoge las
>     incidencias de tráfico en el estado. Se puede consultar en:
>     <https://opendata.esri.es/datasets/a64659151f0a42c69a38563e9d006c6b_0>
>
>     El acceso se realiza atacando a la API que devolverá un documento
>     JSON. En el propio portal hay un generador de url en función de
>     los campos que se necesiten.
>
> -   **Datos de afectación metereológica**. En especial interesan las
>     previsiones de fenómenos atmosféricos adversos que puedan ocurrir
>     en la red nacional de carreteras. Más información:
>     <http://www.aemet.es/es/datos_abiertos/AEMET_OpenData>
>
>     El acceso es también por API REST, siendo necesario la obtención
>     de una Key de identificación.
>
> En cuanto a la **calidad del dato**, al ser fuentes abiertas vienen
> con una calidad del dato alta. Se ha de tener en cuenta la
> desnormalización de los datos, tanto en el caso de los datos de la DGT
> como los de la AEMET.
>
> ### Data Preparation
>
> En este apartado, siguiendo el método CRISP-DM, realizamos las tareas
> de selección de los datos principales, con el descubrimiento de las
> tablas, registros y atributos necesarios. Además, se realizará la
> limpieza y el formateo del dato en caso necesario. Por otro lado, se
> buscan los campos principales para realizar la integración de los
> datos. Al finalizar esta fase ya tendríamos definido un **modelo
> lógico de datos**.
>
> Para los datos provenientes de las operadoras de telefonía, y según
> los ficheros de ejemplo, encontramos la siguiente estructura:
>
> -   Fichero **PobxCeldasOrigen**
>
> ![](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-367F390D.png)
>
> -   Fichero **PobxCeldasDestino**
>
> ![](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-707BCC32.png)
>
> -   Fichero **Flujos**
>
> ![](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-27D2FB4A.png)
>
> La fecha está contenida en el directorio con el siguiente formato:
> "DIA_01ABR_2020". Por lo que se tendrá que extraer del nombre para
> añadirlo al modelo.
>
> No obstante, se tendrá que trabajar con la operadora para que
> suministren esta información mediante API.
>
> De la visualización de las tablas, podemos descubrir las siguientes
> dimensiones:
>
> -   **Poblaciones**. Con la lista de poblaciones de origen y destino.
>
> El campo celda puede despreciarse en un inicio, dado que para el
> resultado final no aporta, quedando sólo para comprobación de errores.
>
> De todos los campos que ofrece la API de la DGT, sólo interesan los
> siguientes:
>
> -   autonomia, carretera, causa, fechahora\_, hacia, nivel, pk_final,
>     pk_inicial, poblacion, provincia, sentido, tipo, actualizad, x, y.
>
> Este es un ejemplo de dato devuelto por el API
>
>      {
>              "attributes": {
>                 "autonomia": "CASTILLA-LEON",
>                 "carretera": "CL-505",
>                 "causa": "NIEBLA",
>                 "fechahora_": "2021-02-03 17:02",
>                 "hacia": "Ambos",
>                 "nivel": "VERDE",
>                 "pk_final": 42.9,
>                 "pk_inicial": 13,
>                 "poblacion": "HERRADON (EL)",
>                 "provincia": "AVILA",
>                 "sentido": "Ambos sentidos",
>                 "tipo": "METEOROLOGICA",
>                 "x": 40.6099478,
>                 "y": -4.5569102,
>                 "actualizad": "2021-02-05 14:30"
>
> Como se puede comprobar, los datos vienen desnormalizados, por lo que
> será necesario una normalización. Para ello se proponen las siguientes
> dimensiones:
>
> -   **Jerarquía Geográfica**. Con las dimensiones:
>
>     -   **Pais**, **Autonomía**, **Provincia**, **Población**.
>
> -   **Carreteras**. Con la nomenclatura de carreteras estatales.
>
> -   **Gravedad**. Incorpora el Atributo nivel junto con su descripción
>     para definir a la alerta.
>
> -   **TipoEvento**. Lista de causas que causan las incidencias.
>
> Para los datos metereológicos utilizaremos en una primera fase inicial
> la parte de avisos. El formato de la petición se puede consultar en la
> siguiente dirección:
> <https://opendata.aemet.es/dist/index.html?#/avisos_cap>. La petición
> devuelve un XML con cada una de las alertas. A continuación se muestra
> un ejemplo de un extracto del documento
>
> ![](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-5B110911.png)
>
> Como se puede comprobar en la captura, los datos también se encuentran
> desnormalizados, por los que definen las siguientes dimensiones:
>
> -   **Población**. Con la lista de poblaciones afectadas
>
> -   **TipoEvento.** Listado de eventos metereológicos. Atributo
>     "event".
>
> -   **Gravedad**. Atributo "Severity".
>
> Como se puede comprobar, se intenta que las **dimensiones sean
> conformadas** en todos los modelos con el fin de ir a un modelo único
> de datos. Por otro lado, el resto de atributos enriquecen la tabla de
> hechos con la transacción. Es especialmente interesante ver que en el
> caso de la DGT contamos con las coordenadas geoespaciales, interesante
> de cara a la presentación en mapa. No es así en el caso de la AEMET.
>
> A continuación se muestra el esquema lógico de las dimensiones
> planteadas.
>
> ![](C:/Users/jesus.gonzalez/AppData/Local/RStudio/tmp/paste-99E6E422.png)
>
> En azul se muestran las tablas de hechos del modelo, en verde las
> dimensiones. El reto de este proyecto será integrar el flujo del
> transito con las incidencias en una única tabla de hechos.
>
> ### Modeling
>
> Esta fase se aplican las técnicas de modelado necesarias para
> conseguir un modelo de datos óptimo. Tal y como se muestra en el
> diagrama de fases, es una fase que suele volver sobre la fase de
> preparación de datos, bien para solucionar problemas, o para
> enriquecer los datos. Además de la construcción de los modelos, será
> necesaria el diseño de los test que se utilizarán para evaluar los
> modelos.
>
> Para el proyecto que estamos realizando, nos enfrentamos a un problema
> de clasificación, en el que en función de la historia pasada del flujo
> de movimientos del tráfico, y alimentado con los datos presentes
> proporcionados por las operadoras de telefonía, y de los futuros, con
> la predicción a una semana vista de los incidentes metereológicos, se
> realiza una clasificación a futuro de la congestión de las vías de
> tráfico. La variable target está definida por el nivel de congestión
> de la vía, y la establecemos en tres niveles:
>
> -   **Nivel 1** - Verde: Sin incidencias.
>
> -   **Nivel 2** - Amarillo. Con incidencias, pero sin congestión.
>
> -   **Nivel 3** - Rojo. Congestión.
>
> Se probarán con diferentes modelos de clasificación para estimar la
> mejor bondad entre ellos, escogiendo el modelo campeón.
>
> -   logistic regression
>
> -   support vector machines
>
> -   random forests
>
> -   deep learning
>
> Se define una separación de la serie del 80 % para el training y el
> 20% restante para el test.
>
> ### Evaluation
>
> Una vez obtenido los modelos necesarios para conseguir los objetivos
> establecidos en la fase inicial, es necesaria una evaluación que
> permita asegurar que se cumplen dichos objetivos. Para ello se emplea
> el plan de test diseñado durante la fase anterior. En caso necesario
> se revisa el proceso y en función de los resultados se determinan los
> próximos pasos a cumplir.
>
> Una vez obtenido el modelo campeón, capaz de predecir por encima de
> los objetivos iniciales del proyecto la congestión de las vías, es el
> momento de extraer las **conclusiones** sobre los resultados
> obtenidos. Es importante ver si el modelo **podrá ser explotado
> comercialmente** antes de avanzar a la siguiente fase.
>
> ### Deployment
>
> Una vez el modelo ha pasado todos los test y tiene la aprobación, es
> necesario definir un plan para su despliegue. Así, la creación de un
> modelo final no es el final de proyecto, más bien supone el llegar a
> un hito dentro de él. Un modelo puesto en producción necesita de una
> monitorización y de un mantenimiento. Además, es recomendable la
> publicación de resultados que ayuden a entender si se ha logrado
> conseguir los objetivos inicialmente pedidos en la fase 1. Es bastante
> común que tras la puesta en producción del proyecto se generen nuevas
> espectativas que haga replantearse el modelo (proyecto) generado. Es
> por ello, que CRISP-DM describe el ciclo de vida del proyecto de
> minería de datos en en entorno circular, en donde la salida realimenta
> la entrada de un nuevo ciclo que busca la mejora continua del negocio.
>
> En esta fase de despliegue se busca la optimización del modelo, siendo
> probado en un entorno real. Por eso en esta primera fase se diseña una
> Web rudimentaria en donde poder consultar los resultados. Se busca un
> target de clientes selectos para que prueben durante un tiempo
> prudencial, buscando su feed-back.
>
> Una vez el modelo se considere estable y listo para su explotación a
> gran escala, se diseñará otra fase del proyecto, esta vez dirigida a
> mejorar el look & feel del usuario. Para ello, se propone el diseño de
> una apk en android e IOS, así como de una WEB para la explotación de
> los datos.
>
> ##### Otras fuentes consultadas
>
> [<https://www.sngular.com/es/data-science-crisp-dm-metodologia/>](https://www.sngular.com/es/data-science-crisp-dm-metodologia/){.uri}
>
> [<https://exde.wordpress.com/2009/03/13/a-visual-guide-to-crisp-dm-methodology/>](https://exde.wordpress.com/2009/03/13/a-visual-guide-to-crisp-dm-methodology/){.uri}
>
> <http://public.dhe.ibm.com/software/analytics/spss/documentation/modeler/15.0/es/CRISP-DM.pdf>

## Ejercicio 2:

A partir del juego de datos disponible en el siguiente enlace
<http://archive.ics.uci.edu/ml/datasets/adult> , realiza las tareas
previas a la generación de un modelo de minería de datos explicados en
el Módulo 2. Puedes utilizar de referencia el ejemplo del Titánic.

Nota: Si lo deseas puedes utilizar otro conjunto de datos propio o de
algún repositorio datos abiertos siempre que sea similar en diversidad
de tipo de variables al propuesto.

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Carga de las librerías necesarias
# https://cran.r-project.org/web/packages/ggplot2/index.html
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
# https://cran.r-project.org/web/packages/dplyr/index.html
if (!require('dplyr')) install.packages('dplyr'); library('dplyr')
```

### Carga del dataset

Cargamos el juego de datos

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Cargamos el juego de datos

col_names <- c('age', 'workclass', 'fnlwgt', 'education', 'education-num',
'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'income')

totalData <- read.csv('./data/adult.data',header =F,  stringsAsFactors = T, row.names = NULL, sep=',', col.names = col_names)


filas=dim(totalData)[1]

# Verificamos la estructura del fichero

str(totalData)
```

> Se han cargado 32561 registros. El objetivo es predecir si los
> ingresos de una persona superan o no los 50.000\$ (variable target
> **income** ). Contamos con varias variables categóricas como son la
> educación, el estado civil, la raza y la ocupación, entre otras. A
> continuación se muestra una tabla con los tipos y la descripción de
> las variables.

+-----------------------------------+-----------------------------------+
| Variable name                     | description                       |
+===================================+===================================+
| age                               | continuous.                       |
+-----------------------------------+-----------------------------------+
| workclass                         | Private, Self-emp-not-inc,        |
|                                   | Self-emp-inc, Federal-gov,        |
|                                   | Local-gov, State-gov,             |
|                                   | Without-pay, Never-worked.        |
+-----------------------------------+-----------------------------------+
| fnlwgt                            | continuous.                       |
+-----------------------------------+-----------------------------------+
| education                         | Bachelors, Some-college, 11th,    |
|                                   | HS-grad, Prof-school, Assoc-acdm, |
|                                   | Assoc-voc, 9th, 7th-8th, 12th,    |
|                                   | Masters, 1st-4th, 10th,           |
|                                   | Doctorate, 5th-6th, Preschool.    |
+-----------------------------------+-----------------------------------+
| education-num                     | continuous.                       |
+-----------------------------------+-----------------------------------+
| marital-status                    | Married-civ-spouse, Divorced,     |
|                                   | Never-married, Separated,         |
|                                   | Widowed, Married-spouse-absent,   |
|                                   | Married-AF-spouse.                |
+-----------------------------------+-----------------------------------+
| occupation                        | Tech-support, Craft-repair,       |
|                                   | Other-service, Sales,             |
|                                   | Exec-managerial, Prof-specialty,  |
|                                   | Handlers-cleaners,                |
|                                   | Machine-op-inspct, Adm-clerical,  |
|                                   | Farming-fishing,                  |
|                                   | Transport-moving,                 |
|                                   | Priv-house-serv, Protective-serv, |
|                                   | Armed-Forces.                     |
+-----------------------------------+-----------------------------------+
| relationship                      | Wife, Own-child, Husband,         |
|                                   | Not-in-family, Other-relative,    |
|                                   | Unmarried.                        |
+-----------------------------------+-----------------------------------+
| race                              | White, Asian-Pac-Islander,        |
|                                   | Amer-Indian-Eskimo, Other, Black. |
+-----------------------------------+-----------------------------------+
| sex                               | Female, Male.                     |
+-----------------------------------+-----------------------------------+
| capital-gain                      | continuous.                       |
+-----------------------------------+-----------------------------------+
| capital-loss                      | continuous.                       |
+-----------------------------------+-----------------------------------+
| hours-per-week                    | continuous.                       |
+-----------------------------------+-----------------------------------+
| native-country                    | United-States, Cambodia, England, |
|                                   | Puerto-Rico, Canada, Germany,     |
|                                   | Outlying-US(Guam-USVI-etc),       |
|                                   | India, Japan, Greece, South,      |
|                                   | China, Cuba, Iran, Honduras,      |
|                                   | Philippines, Italy, Poland,       |
|                                   | Jamaica, Vietnam, Mexico,         |
|                                   | Portugal, Ireland, France,        |
|                                   | Dominican-Republic, Laos,         |
|                                   | Ecuador, Taiwan, Haiti, Columbia, |
|                                   | Hungary, Guatemala, Nicaragua,    |
|                                   | Scotland, Thailand, Yugoslavia,   |
|                                   | El-Salvador, Trinadad&Tobago,     |
|                                   | Peru, Hong, Holand-Netherlands.   |
+-----------------------------------+-----------------------------------+
| income                            | Two values: \>50K, \<=50K.        |
+-----------------------------------+-----------------------------------+

Antes de cualquier análisis, vamos a comprobar que no existan valores
nulos en el dataset.

```{r}
duplicated_row_number <- nrow(totalData) - nrow(unique(totalData))
if(duplicated_row_number != 0) {print(paste('Existen registros duplicados en el dataset: ', duplicated_row_number, 'registros.'))} else {print('Dataset sin registros duplicados')}

totalData <- unique(totalData)
```

Se ha limpiado el dataset de registros duplicados.

### **Análisis Exploratorio**

A continuación, sacaremos las estadísticas básicas del dataset .

```{r}
summary(totalData)
```

> De la primera observación de las estadísticas básicas podemos hacer
> mención de los siguientes puntos significativos:
>
> -   **edad**: Esta variable se encuentra ligeramente desbalanceada
>     hacia valores de mayor edad, mostrándose la media escorada hacia
>     la derecha respecto a la mediana. Además si nos fijamos en el
>     valor máximo respecto al tercer cuartil, podemos sospechar de la
>     existencia de outilers.
>
> -   **workclass**: Muestra un valor con "?" para valores desconocidos.
>     Se tendrá que hacer tratamiento de él.
>
> -   **education** : Predominan los estudiantes de grado ("High
>     school"). Por el otro lado, encontramos el segundo valor
>     mayoritario en "Some-college", estudiantes que han interrumpido
>     sus estudios antes de tener carrera universitaria. Será
>     interesante poder ver la incidencia que tienen los estudios
>     superiores en la variable target. Un punto interesante en esta
>     variable, es que por su naturaleza, podría interesarnos que
>     siguiera el orden natural de estudios: "Preschool, 1st-4th,
>     5th-6th, 7th-8th, 9th, 10th, 11th, 12th, Bachelors, HS-grad,
>     Masters, ..."
>
> -   **capital.gain** y **capital.loss**: Si examinamos las medidas de
>     tendencia central media y mediana, vemos que se encuentran muy
>     distanciados entre ambas. Podríamos pasarlas a categóricas
>     binarias para expresar las pérdidas y ganancias.
>
> -   **Sex** y **race**: Examinando estas dos variables, nos damos
>     cuenta del enorme sesgo que nos encontramos en los datos, tanto en
>     cuestión de sexo como de raza. Se tendrá que tener en cuenta a la
>     hora realizar predicciones para que no impacte el sesgo. En el
>     caso de race, predomina la raza blanca, y en sexo los hombres,
>     superando por el doble a las mujeres.
>
> -   **native.country**: Debido a la enorme desproporción entre
>     ciudadanos norteamericanos y el resto, se propone la agrupación en
>     dos grupos, nortamericanos y extranjeros, con el fin de equilibrar
>     la variable.
>
> -   **Income**: La variable destino muestra también un desbalanceo
>     entre las muestras que son menores de 50k respecto las que superan
>     esta cifra.

A continuación vamos a visualizar y tratar los valores nulos

```{r}
colSums(is.na(totalData))
colSums(totalData=="")
```

Aunque en un inicio no encontremos valores nulos, hemos visto
anteriormente que alguna variable los tiene ya codificados.

### **Preprocesamiento de las variables**

#### Variable edad

Para la variable continua edad vamos a discretizarla por intervalos.

```{r}
summary(totalData$age)
```

```{r}
totalData["segmento_edad"] <- cut(totalData$age, breaks = c(0, 20, 30, 40, 50, 60, 100), labels = c("0-19", "20-29", "30-39","40-49","50-59","60-99"))
table(totalData$segmento_edad)
```

Aprovechemos la segmentación de la variable edad para ver el
comportamiento respecto la variable objetivo.

```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data=totalData, aes(x=segmento_edad,fill=income))+geom_bar()
```

Visualmente se puede ver que los mayores ingresos se centran en las
franja de edades comprendidas entre los 30 y 49 años, existiendo mayores
ingresos en la franja de 40 a 49 años. Aunque para un estudio en mayor
profundidad sería aconsejable el calcular el porcentaje de ingresos por
franja de edad. Este dato nos dará datos empíricos más fiables.

#### Variable education

En cuanto a la variable education, si examinamos los valores que toma,
podemos ver que podemos segmentarla en tres grupos. Para ello nos
ayudamos de la variable education.num que contiene la ordenación del
factor.

```{r}
totalData[, c('education', 'education.num')] %>% unique() %>% arrange(education.num)
```

La segmentación la realizaremos según el siguiente criterio:

-   Estudios básicos: 10th, 11th, 12th, 1st-4th, 5th-6th, 7th-8th, 9th,
    Preschool.

-   Estudios médios: HS-grad, Some-college, Assoc-voc, Assoc-acdm.

-   Estudios superiores: Doctorate, Masters, Prof-school, Bachelors.

    ```{r}

    education_group_labels <- c('basic', 'middle', 'higher')
    totalData$education_group <- cut(totalData$education.num, c(0, 8, 12, 16), labels= education_group_labels)
    totalData[, c('education', 'education.num', 'education_group')] %>% unique() %>% arrange(education.num) %>% print()
    ```

#### Eliminación del espacio inicial en factor.

En las variables tipo factor, nos encontramos que hay un espacio inicial
que debemos de eliminar.

```{r}
column_name_factor <- c('workclass', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income')

  for (column_name in column_name_factor) {
    print(paste('>> Variable: ', column_name, ' sin tratamiento'))
    print(levels(totalData[,column_name]))
    levels(totalData[,column_name]) <- trimws(levels(totalData[,column_name]))
    print(paste('>> Variable: ', column_name, ' tratada'))
    print(levels(totalData[,column_name]))
    print('------------------------')
  }


```

#### Tratamiento de los valores desconocidos

En este dataset hemos observado que se utiliza el carácter "?" para los
valores desconocidos en las variables de tipo factor. Para mejorar la
interpretabilidad de los resultados, vamos a cambiarlo por
"desconocido".

Por ejemplo, en la variable native.country encontramos este valor.

```{r}
levels(totalData$native.country)
```

```{r}
for (column_name in column_name_factor) {
  pos <- match('?', levels(totalData[,column_name]))
  if (!is.na(pos)) {
    levels(totalData[,column_name])[pos] <- 'desconocido' 
  }
}
levels(totalData$native.country)
```

#### Agrupación de países

Si examinamos la variable native.country, vemos que la proporción entre
los de United States y el resto no se encuentra balanceada.

```{r}
ggplot(totalData) + geom_bar(aes(x= native.country, fill= native.country)) 
```

Vamos a generar una nueva variable de análisis que contemple tres
opciones, los ciudadanos norteamericanos, de otras nacionalidades y los
desconocidos.

```{r}
totalData[totalData$native.country == 'United-States', 'migrant'] <- 'No'
totalData[totalData$native.country == 'desconocido', 'migrant'] <- 'unknow'
totalData[(totalData$native.country != 'United-States' & totalData$native.country!= 'desconocido'), 'migrant'] <- 'Yes'
table(totalData$migrant)
```

Aunque ha crecido la representatividad de los ciudadanos no nacidos en
Estados Unidos, la diferencia sigue siendo grande. Si lo miramos
visualmente, la diferencia a

```{r}
ggplot(totalData) + geom_bar(aes(x= migrant, fill= migrant))
```

### Procesos de análisis visuales del juego de datos

#### Análisis variable workclass

Vamos a relacionar las relaciones entre clase de trabajo (workclass) e
ingresos

```{r}
ggplot(data=totalData,aes(x=workclass,fill=income))+geom_bar()+ coord_flip()
```

**La clase Private**, es claramente representativa de la serie, y es en
donde se da la mayoría de **ingresos superiores a los 50k**. Además de
comparar entre clases, vamos ver en donde esta ganancia es más acusada
dentro de la clase.

```{r}
total_workclass <- totalData %>% select(workclass, income) %>% group_by(workclass) %>% count()
workclass_moreThan_50k <- totalData %>% select(workclass, income) %>% filter(income == '>50K') %>% group_by(workclass) %>% count()
total_workclass_df <- merge(total_workclass, workclass_moreThan_50k, by = 'workclass', all = T)
colnames(total_workclass_df) <- c('workclass', 'total', '>50k')
total_workclass_df[is.na(total_workclass_df$`>50k`), '>50k'] <- 0
total_workclass_ratio <-mutate(total_workclass_df, "ratio"= (`>50k`/total)*100)
total_workclass_ratio
```

Vemos que mayor porcentaje de personas con ingresos superiores a los 50
k se encuentra en los **empleados por cuenta propia**.

#### Análisis variable education

Examinemos ahora las personas con estudios superiores

```{r}
ggplot(data=totalData,aes(x=education_group,fill=income))+geom_bar()
```

Vemos que la proporción de personas con estudios superiores que ganan
por encima de los 50k es de aproximadamente la mitad. En cambio, para
las personas con estudios medios se ve una gran desproporción. Vamos a
mirar dentro del grupo de estudios medios si destaca alguna clase sobre
otra.

```{r}
middle_education <- totalData[totalData$education_group == 'middle', c('education', 'income')]
ggplot(data=middle_education,aes(x=education,fill=income))+geom_bar()
```

Ninguna clase es representativa destacando ligeramente los que han
acabado estudios de High scool.

#### Análisis educación y país de nacimiento

Involucremos el país de nacimiento en la estadística de la educación
para ver los resultados

```{r}
totalData %>% filter(income == '>50K') %>% select(education_group, migrant) %>% table()

```

Podemos observar de los resultados de la tabla que la proporción entre
las personas nacidas fuera de EEUU que consiguen ganar más de 50k es de
casi el doble para los que tienen estudios superiores. Esta proporción
no se da entre las personas nacidas en EEUU, en el que se observa una
proporción similar entre los que han estudiado estudios medios y los que
tienen superiores. No obstante, no podemos olvidar la desproporción que
existen entre el número de personas que obtienen estos ingreso dentro de
la misma clase, estudios medios respecto a superiores, para no obtener
conclusiones erróneas.

#### Análisis variable sexo

Primero examinemos los datos de esta variable respecto a los ingresos.

```{r}
ggplot(data=totalData,aes(x=sex,fill=income))+geom_bar()
```

Como era de esperar, se observa una gran desproporción entre hombres y
mujeres que ganan más de 50k. Miremos estos resultados en términos
relativos

```{r}
total_sex <- totalData %>% group_by(sex) %>% count()
total_sex_morethan50k <- totalData %>% filter(income == '>50K') %>% group_by(sex) %>% count()
total_sex_df <- merge(total_sex, total_sex_morethan50k, by= 'sex', all =T)
mutate(total_sex_df, ratio= (n.y / n.x)*100)
```

La proporción entre los hombres que superan los 50k de ingresos respecto
a las mujeres es de casi el triple.

#### Análisis sexo respecto raza

Miremos si esta relación se relaciona con la raza.

```{r}
ggplot(data=totalData,aes(x=sex,fill=income))+geom_bar(position="fill") + facet_wrap(~race)
```

Podemos observar como continúa la desproporción entre mujeres y hombres
respecto a los ingresos. Por otro lado, aunque la raza blanca es la que
obtiene la mayor proporción, encontramos como la asiática tiene una
proporción similar, aunque no olvidemos que el resultado es respecto a
su propia clase, con una población mucho menor que la blanca o la negra.

Podemos preguntarnos si esto tendrá algo que ver con los estudios.

#### Análisis educación respecto raza

```{r}
totalData %>% filter(income == '>50K') %>% select('education_group', 'race') %>% table()
```

En efecto, vemos que en la población asiática, la proporción entre
personas que obtienen estos ingresos prevalece la que tiene estudios
superiores. Sorprende que en el caso de la población negra esto no
sucede, siendo la que tiene estudios medios la predominante.

#### Análisis horas a la semana

¿Cuánto influye las horas de la semana respecto a tener unos ingresos
más elevados?

```{r}
ggplot(data=totalData,aes(x=hours.per.week,fill=income)) + geom_histogram(binwidth =5,position="fill")
```

Es interesante notar que para ganar de más de 50k tienes que trabajar
más de las 40h semanales.

#### Análisis horas a la semana respecto el sexo

Si profundizamos en la diferencia respecto al sexo

```{r}
ggplot(data=totalData,aes(x=hours.per.week,fill=income)) + geom_histogram(binwidth =10,position="fill") + facet_wrap(~sex) + geom_line(y = 0.25)
```

Hemos puesto una linea de corte en el 25% para que sea visualmente más
impactante. En el caso de las mujeres, vemos que aunque dedique muchas
más horas, no logran superar esta barrera.

#### Análisis horas a la semana respecto la variable raza

Veamos los resultados al extender el mismo planteamiento del análisis de
la variable horas semanales a la variable raza.

```{r}
ggplot(data=totalData,aes(x=hours.per.week,fill=income)) + geom_histogram(binwidth =10,position="fill") + facet_wrap(~race) + geom_line(y = 0.25)
```

En este caso salvo las dos distribuciones minoritarias, índicos y Other,
el resto supera el 25% de población con ingresos superiores a los 50k
cuando se superan las 40h semanales.

### Conclusiones finales

------------------------------------------------------------------------

# Criterios de evaluación

------------------------------------------------------------------------

Ejercicio 1

Concepto y peso en la nota final

El objetivo del proyecto está correctamente definido con suficiente
concreción y se puede resolver con técnicas de minería de datos. 15%

Las fases del ciclo de vida están correctamente expresadas. Los ejemplos
son clarificadores. La justificación y argumentación de las decisiones
que se han tomado. 20%

Ejercicio 2

Se carga la base de datos, se visualiza su estructura y se explica los
hechos básicos que explican los datos. 5%

Se estudia si existen atributos vacíos o en diferentes escalas que haya
que normalizar. Si es el caso se adoptan medidas para tratar estos
atributos. Se construye una nueva variable útil a partir de las
existentes. Se discretiza algún atributo. 20%

Se analizan los datos de forma visual y extraen conclusiones tangibles.
Hay que elaborar un discurso coherente y con conclusiones claras. 30%

Se trata en profundidad algún otro aspecto respecto a los datos
presentado en el Módulo 2 10%
